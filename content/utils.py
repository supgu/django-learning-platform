from django.db.models import Count, Q, Avg
from django.contrib.auth.models import User
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import numpy as np
from collections import defaultdict
import requests
import json

from .models import CreativeContent, Tag, Like, Favorite, Rating, UserActivity


def get_client_ip(request):
    """è·å–å®¢æˆ·ç«¯IPåœ°å€"""
    x_forwarded_for = request.META.get('HTTP_X_FORWARDED_FOR')
    if x_forwarded_for:
        ip = x_forwarded_for.split(',')[0]
    else:
        ip = request.META.get('REMOTE_ADDR')
    return ip


def record_user_activity(user, action, content=None, description=""):
    """è®°å½•ç”¨æˆ·æ´»åŠ¨"""
    if user.is_authenticated:
        UserActivity.objects.create(
            user=user,
            action=action,
            content=content,
            description=description
        )


def get_user_preferences(user):
    """è·å–ç”¨æˆ·åå¥½æ ‡ç­¾"""
    # åŸºäºç”¨æˆ·ç‚¹èµã€æ”¶è—ã€è¯„åˆ†çš„å†…å®¹è·å–åå¥½æ ‡ç­¾
    liked_contents = CreativeContent.objects.filter(
        likes__user=user
    ).prefetch_related('tags')
    
    favorited_contents = CreativeContent.objects.filter(
        favorites__user=user
    ).prefetch_related('tags')
    
    rated_contents = CreativeContent.objects.filter(
        ratings__user=user,
        ratings__score__gte=4  # é«˜åˆ†è¯„ä»·
    ).prefetch_related('tags')
    
    # ç»Ÿè®¡æ ‡ç­¾æƒé‡
    tag_weights = defaultdict(float)
    
    # ç‚¹èµæƒé‡ 1
    for content in liked_contents:
        for tag in content.tags.all():
            tag_weights[tag.id] += 1.0
    
    # æ”¶è—æƒé‡ 2
    for content in favorited_contents:
        for tag in content.tags.all():
            tag_weights[tag.id] += 2.0
    
    # é«˜åˆ†è¯„ä»·æƒé‡ 1.5
    for content in rated_contents:
        for tag in content.tags.all():
            tag_weights[tag.id] += 1.5
    
    # è¿”å›æƒé‡æœ€é«˜çš„æ ‡ç­¾
    sorted_tags = sorted(tag_weights.items(), key=lambda x: x[1], reverse=True)
    return [tag_id for tag_id, weight in sorted_tags[:10]]


def get_content_similarity_matrix():
    """è®¡ç®—å†…å®¹ç›¸ä¼¼åº¦çŸ©é˜µï¼ˆåŸºäºTF-IDFï¼‰"""
    contents = CreativeContent.objects.filter(privacy='public')
    
    if not contents.exists():
        return {}, []
    
    # å‡†å¤‡æ–‡æœ¬æ•°æ®
    texts = []
    content_ids = []
    
    for content in contents:
        # ç»„åˆæ ‡é¢˜ã€å†…å®¹å’Œæ ‡ç­¾
        text = f"{content.title} {content.content} {' '.join([tag.name for tag in content.tags.all()])}"
        texts.append(text)
        content_ids.append(content.id)
    
    # è®¡ç®—TF-IDF
    try:
        vectorizer = TfidfVectorizer(
            max_features=1000,
            stop_words=None,  # ä¸­æ–‡éœ€è¦è‡ªå®šä¹‰åœç”¨è¯
            ngram_range=(1, 2)
        )
        tfidf_matrix = vectorizer.fit_transform(texts)
        
        # è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
        similarity_matrix = cosine_similarity(tfidf_matrix)
        
        # æ„å»ºç›¸ä¼¼åº¦å­—å…¸
        similarity_dict = {}
        for i, content_id in enumerate(content_ids):
            similarity_dict[content_id] = {
                content_ids[j]: similarity_matrix[i][j] 
                for j in range(len(content_ids)) if i != j
            }
        
        return similarity_dict, content_ids
    except Exception as e:
        print(f"è®¡ç®—ç›¸ä¼¼åº¦çŸ©é˜µé”™è¯¯: {e}")
        return {}, []


def get_collaborative_filtering_recommendations(user, limit=10):
    """ååŒè¿‡æ»¤æ¨è"""
    # è·å–ç”¨æˆ·çš„è¯„åˆ†æ•°æ®
    user_ratings = Rating.objects.filter(user=user).values_list('content_id', 'score')
    user_rated_contents = dict(user_ratings)
    
    if not user_rated_contents:
        return []
    
    # æ‰¾åˆ°ç›¸ä¼¼ç”¨æˆ·
    similar_users = []
    all_users = User.objects.exclude(id=user.id)
    
    for other_user in all_users:
        other_ratings = Rating.objects.filter(user=other_user).values_list('content_id', 'score')
        other_rated_contents = dict(other_ratings)
        
        # è®¡ç®—ç”¨æˆ·ç›¸ä¼¼åº¦ï¼ˆåŸºäºå…±åŒè¯„åˆ†çš„å†…å®¹ï¼‰
        common_contents = set(user_rated_contents.keys()) & set(other_rated_contents.keys())
        
        if len(common_contents) >= 2:  # è‡³å°‘æœ‰2ä¸ªå…±åŒè¯„åˆ†
            similarity = calculate_user_similarity(
                user_rated_contents, 
                other_rated_contents, 
                common_contents
            )
            if similarity > 0.3:  # ç›¸ä¼¼åº¦é˜ˆå€¼
                similar_users.append((other_user, similarity))
    
    # æ ¹æ®ç›¸ä¼¼ç”¨æˆ·æ¨èå†…å®¹
    recommendations = []
    similar_users.sort(key=lambda x: x[1], reverse=True)  # æŒ‰ç›¸ä¼¼åº¦æ’åº
    
    for similar_user, similarity in similar_users[:5]:  # å–å‰5ä¸ªç›¸ä¼¼ç”¨æˆ·
        # è·å–ç›¸ä¼¼ç”¨æˆ·é«˜åˆ†è¯„ä»·çš„å†…å®¹
        high_rated_contents = CreativeContent.objects.filter(
            ratings__user=similar_user,
            ratings__score__gte=4,
            privacy='public'
        ).exclude(
            id__in=user_rated_contents.keys()
        ).distinct()
        
        for content in high_rated_contents:
            if content not in [rec[0] for rec in recommendations]:
                score = similarity * content.ratings.filter(user=similar_user).first().score
                recommendations.append((content, score))
    
    # æŒ‰æ¨èåˆ†æ•°æ’åº
    recommendations.sort(key=lambda x: x[1], reverse=True)
    return [content for content, score in recommendations[:limit]]


def calculate_user_similarity(user1_ratings, user2_ratings, common_contents):
    """è®¡ç®—ç”¨æˆ·ç›¸ä¼¼åº¦ï¼ˆçš®å°”é€Šç›¸å…³ç³»æ•°ï¼‰"""
    if not common_contents:
        return 0
    
    # è®¡ç®—å¹³å‡åˆ†
    user1_scores = [user1_ratings[content_id] for content_id in common_contents]
    user2_scores = [user2_ratings[content_id] for content_id in common_contents]
    
    user1_mean = np.mean(user1_scores)
    user2_mean = np.mean(user2_scores)
    
    # è®¡ç®—çš®å°”é€Šç›¸å…³ç³»æ•°
    numerator = sum((user1_ratings[content_id] - user1_mean) * 
                   (user2_ratings[content_id] - user2_mean) 
                   for content_id in common_contents)
    
    user1_sq_sum = sum((user1_ratings[content_id] - user1_mean) ** 2 
                      for content_id in common_contents)
    user2_sq_sum = sum((user2_ratings[content_id] - user2_mean) ** 2 
                      for content_id in common_contents)
    
    denominator = np.sqrt(user1_sq_sum * user2_sq_sum)
    
    if denominator == 0:
        return 0
    
    return numerator / denominator


def get_content_based_recommendations(user, limit=10):
    """åŸºäºå†…å®¹çš„æ¨è"""
    # è·å–ç”¨æˆ·åå¥½æ ‡ç­¾
    preferred_tag_ids = get_user_preferences(user)
    
    if not preferred_tag_ids:
        return []
    
    # è·å–ç”¨æˆ·å·²ç»äº¤äº’è¿‡çš„å†…å®¹
    interacted_content_ids = set()
    
    # å·²ç‚¹èµçš„å†…å®¹
    liked_ids = Like.objects.filter(user=user).values_list('content_id', flat=True)
    interacted_content_ids.update(liked_ids)
    
    # å·²æ”¶è—çš„å†…å®¹
    favorited_ids = Favorite.objects.filter(user=user).values_list('content_id', flat=True)
    interacted_content_ids.update(favorited_ids)
    
    # å·²è¯„åˆ†çš„å†…å®¹
    rated_ids = Rating.objects.filter(user=user).values_list('content_id', flat=True)
    interacted_content_ids.update(rated_ids)
    
    # ç”¨æˆ·è‡ªå·±åˆ›å»ºçš„å†…å®¹
    authored_ids = CreativeContent.objects.filter(author=user).values_list('id', flat=True)
    interacted_content_ids.update(authored_ids)
    
    # æ¨èåŒ…å«åå¥½æ ‡ç­¾çš„å†…å®¹
    recommended_contents = CreativeContent.objects.filter(
        tags__id__in=preferred_tag_ids,
        privacy='public'
    ).exclude(
        id__in=interacted_content_ids
    ).annotate(
        tag_match_count=Count('tags', filter=Q(tags__id__in=preferred_tag_ids)),
        avg_rating=Avg('ratings__score'),
        popularity_score=Count('likes') + Count('favorites') * 2
    ).order_by(
        '-tag_match_count',
        '-avg_rating',
        '-popularity_score',
        '-created_at'
    ).distinct()[:limit]
    
    return list(recommended_contents)


def get_recommendations_for_user(user, limit=10):
    """ä¸ºç”¨æˆ·è·å–æ¨èå†…å®¹ï¼ˆæ··åˆæ¨èï¼‰"""
    recommendations = []
    
    # 1. ååŒè¿‡æ»¤æ¨èï¼ˆæƒé‡40%ï¼‰
    try:
        cf_recommendations = get_collaborative_filtering_recommendations(user, limit//2)
        recommendations.extend(cf_recommendations)
    except Exception as e:
        print(f"ååŒè¿‡æ»¤æ¨èé”™è¯¯: {e}")
    
    # 2. åŸºäºå†…å®¹çš„æ¨èï¼ˆæƒé‡60%ï¼‰
    try:
        cb_recommendations = get_content_based_recommendations(user, limit)
        recommendations.extend(cb_recommendations)
    except Exception as e:
        print(f"åŸºäºå†…å®¹æ¨èé”™è¯¯: {e}")
    
    # 3. çƒ­é—¨å†…å®¹è¡¥å……
    if len(recommendations) < limit:
        # è·å–ç”¨æˆ·å·²äº¤äº’çš„å†…å®¹ID
        interacted_ids = set()
        if hasattr(user, 'like_set'):
            interacted_ids.update(Like.objects.filter(user=user).values_list('content_id', flat=True))
        if hasattr(user, 'favorite_set'):
            interacted_ids.update(Favorite.objects.filter(user=user).values_list('content_id', flat=True))
        if hasattr(user, 'rating_set'):
            interacted_ids.update(Rating.objects.filter(user=user).values_list('content_id', flat=True))
        
        # æ’é™¤å·²æ¨èçš„å†…å®¹
        recommended_ids = [content.id for content in recommendations]
        interacted_ids.update(recommended_ids)
        
        popular_contents = CreativeContent.objects.filter(
            privacy='public'
        ).exclude(
            id__in=interacted_ids
        ).exclude(
            author=user
        ).annotate(
            popularity_score=Count('likes') + Count('favorites') * 2 + Count('ratings')
        ).order_by('-popularity_score', '-created_at')[:limit - len(recommendations)]
        
        recommendations.extend(popular_contents)
    
    # å»é‡å¹¶é™åˆ¶æ•°é‡
    seen_ids = set()
    unique_recommendations = []
    for content in recommendations:
        if content.id not in seen_ids:
            seen_ids.add(content.id)
            unique_recommendations.append(content)
            if len(unique_recommendations) >= limit:
                break
    
    return unique_recommendations


def generate_ai_summary(title, content):
    """ä½¿ç”¨DeepSeek AIç”Ÿæˆå†…å®¹æ‘˜è¦"""
    try:
        import requests
        import json
        from django.conf import settings
        
        # æ£€æŸ¥APIé…ç½®
        api_key = getattr(settings, 'DEEPSEEK_API_KEY', None)
        base_url = getattr(settings, 'DEEPSEEK_BASE_URL', 'https://api.deepseek.com')
        
        if not api_key or api_key == 'your-deepseek-api-key-here':
            return f"è¿™æ˜¯ä¸€ä¸ªå…³äº'{title}'çš„åˆ›æ„å†…å®¹ï¼ŒåŒ…å«äº†ä¸°å¯Œçš„æƒ³æ³•å’Œè§è§£ã€‚ï¼ˆè¯·é…ç½®DeepSeek APIå¯†é’¥ï¼‰"
        
        # æ„å»ºè¯·æ±‚
        url = f"{base_url}/chat/completions"
        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {api_key}"
        }
        
        prompt = f"è¯·ä¸ºä»¥ä¸‹åˆ›æ„å†…å®¹ç”Ÿæˆä¸€ä¸ªç®€æ´çš„æ‘˜è¦ï¼ˆä¸è¶…è¿‡100å­—ï¼‰ï¼š\næ ‡é¢˜ï¼š{title}\nå†…å®¹ï¼š{content[:500]}..."
        
        data = {
            "model": "deepseek-chat",
            "messages": [
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å†…å®¹æ‘˜è¦åŠ©æ‰‹ï¼Œèƒ½å¤Ÿä¸ºå„ç§åˆ›æ„å†…å®¹ç”Ÿæˆç®€æ´ã€å‡†ç¡®çš„æ‘˜è¦ã€‚"},
                {"role": "user", "content": prompt}
            ],
            "max_tokens": 150,
            "temperature": 0.7,
            "stream": False
        }
        
        response = requests.post(url, headers=headers, json=data, timeout=30)
        
        if response.status_code == 200:
            result = response.json()
            if 'choices' in result and len(result['choices']) > 0:
                summary = result['choices'][0]['message']['content'].strip()
                return summary
            else:
                return f"è¿™æ˜¯ä¸€ä¸ªå…³äº'{title}'çš„åˆ›æ„å†…å®¹ï¼ŒåŒ…å«äº†ä¸°å¯Œçš„æƒ³æ³•å’Œè§è§£ã€‚"
        else:
            print(f"DeepSeek APIé”™è¯¯: {response.status_code} - {response.text}")
            return f"è¿™æ˜¯ä¸€ä¸ªå…³äº'{title}'çš„åˆ›æ„å†…å®¹ï¼ŒåŒ…å«äº†ä¸°å¯Œçš„æƒ³æ³•å’Œè§è§£ã€‚"
            
    except Exception as e:
        print(f"AIæ‘˜è¦ç”Ÿæˆé”™è¯¯: {e}")
        return f"è¿™æ˜¯ä¸€ä¸ªå…³äº'{title}'çš„åˆ›æ„å†…å®¹ï¼ŒåŒ…å«äº†ä¸°å¯Œçš„æƒ³æ³•å’Œè§è§£ã€‚"


def generate_ai_comment(title, content):
    """ä½¿ç”¨DeepSeek AIç”Ÿæˆå†…å®¹ç‚¹è¯„"""
    try:
        import requests
        import json
        from django.conf import settings
        
        # æ£€æŸ¥APIé…ç½®
        api_key = getattr(settings, 'DEEPSEEK_API_KEY', None)
        base_url = getattr(settings, 'DEEPSEEK_BASE_URL', 'https://api.deepseek.com')
        
        if not api_key or api_key == 'your-deepseek-api-key-here':
            # å¦‚æœæ²¡æœ‰é…ç½®APIï¼Œä½¿ç”¨åŸæ¥çš„éšæœºè¯„è®ºé€»è¾‘
            # æ ¹æ®å†…å®¹é•¿åº¦å’Œæ ‡é¢˜ç”Ÿæˆæ›´ä¸ªæ€§åŒ–çš„è¯„è®º
            import random
            import hashlib
            
            # ä½¿ç”¨å†…å®¹æ ‡é¢˜ä½œä¸ºç§å­ï¼Œç¡®ä¿åŒä¸€å†…å®¹æ€»æ˜¯ç”Ÿæˆç›¸åŒçš„è¯„è®º
            seed = hashlib.md5(title.encode()).hexdigest()
            random.seed(seed)
            
            # æ ¹æ®å†…å®¹ç‰¹å¾é€‰æ‹©ä¸åŒç±»å‹çš„è¯„è®º
            content_length = len(content)
            
            if content_length > 500:
                comments = [
                    "è¿™æ˜¯ä¸€ç¯‡å†…å®¹ä¸°å¯Œçš„æ–‡ç« ï¼ä½œè€…åœ¨è¿™ä¸ªä¸»é¢˜ä¸Šè¿›è¡Œäº†æ·±å…¥çš„æ¢è®¨ï¼Œé€»è¾‘æ¸…æ™°ï¼Œè¡¨è¾¾æµç•…ã€‚",
                    "è¯¦å®çš„å†…å®¹ï¼Œå¯ä»¥çœ‹å‡ºä½œè€…çš„ä¸“ä¸šåŠŸåº•ã€‚è¿™ç§æ·±åº¦åˆ†æå¾ˆæœ‰ä»·å€¼ï¼Œå€¼å¾—ç»†ç»†å“è¯»ã€‚",
                    "é•¿ç¯‡å¤§è®ºå´ä¸å¤±é‡ç‚¹ï¼Œä½œè€…çš„å†™ä½œåŠŸåŠ›ä»¤äººå°è±¡æ·±åˆ»ã€‚å†…å®¹ç»“æ„åˆç†ï¼Œé˜…è¯»ä½“éªŒå¾ˆå¥½ã€‚",
                    "è¿™æ ·çš„æ·±åº¦å†…å®¹åœ¨å½“ä¸‹å¾ˆéš¾å¾—ï¼Œä½œè€…æ˜¾ç„¶åœ¨è¿™ä¸ªé¢†åŸŸæœ‰ç€ä¸°å¯Œçš„ç»éªŒå’Œç‹¬åˆ°çš„è§è§£ã€‚"
                ]
            elif content_length > 200:
                comments = [
                    "ç®€æ´è€Œæœ‰åŠ›çš„è¡¨è¾¾ï¼ä½œè€…ç”¨ä¸å¤šçš„æ–‡å­—ä¼ è¾¾äº†ä¸°å¯Œçš„ä¿¡æ¯ï¼Œå¾ˆæœ‰å¯å‘æ€§ã€‚",
                    "è§‚ç‚¹æ¸…æ™°ï¼Œè®ºè¿°æœ‰æ¡ç†ã€‚è¿™ç§ä¸­ç­‰ç¯‡å¹…çš„å†…å®¹æœ€é€‚åˆå¿«èŠ‚å¥çš„é˜…è¯»éœ€æ±‚ã€‚",
                    "å†…å®¹æ°åˆ°å¥½å¤„ï¼Œæ—¢ä¸å†—é•¿ä¹Ÿä¸ç®€é™‹ã€‚ä½œè€…å¾ˆå¥½åœ°æŠŠæ¡äº†ä¿¡æ¯å¯†åº¦çš„å¹³è¡¡ã€‚",
                    "è¿™æ ·çš„å†…å®¹é•¿åº¦åˆšå¥½ï¼Œæ—¢èƒ½æ·±å…¥ä¸»é¢˜åˆä¸ä¼šè®©è¯»è€…æ„Ÿåˆ°ç–²åŠ³ã€‚å†™å¾—å¾ˆæ£’ï¼"
                ]
            else:
                comments = [
                    "ç®€çŸ­ç²¾æ‚ï¼æœ‰æ—¶å€™æœ€æœ‰åŠ›çš„è¡¨è¾¾å°±æ˜¯è¿™æ ·ç®€æ´æ˜äº†ï¼Œä¸€é’ˆè§è¡€ã€‚",
                    "çŸ­å°ç²¾æ‚çš„å†…å®¹ï¼Œä½†ä¿¡æ¯é‡ä¸å°ã€‚ä½œè€…å¾ˆä¼šæŠ“é‡ç‚¹ï¼Œå€¼å¾—ç‚¹èµï¼",
                    "è¨€ç®€æ„èµ…ï¼Œè¿™ç§ç®€æ´çš„è¡¨è¾¾æ–¹å¼å¾ˆæœ‰åŠ›é‡ã€‚æœŸå¾…çœ‹åˆ°æ›´å¤šè¿™æ ·çš„ç²¾å½©åˆ†äº«ã€‚",
                    "è™½ç„¶ç¯‡å¹…ä¸é•¿ï¼Œä½†å†…å®¹å¾ˆæœ‰ä»·å€¼ã€‚æœ‰æ—¶å€™ç®€å•çš„è¯è¯­æœ€èƒ½æ‰“åŠ¨äººå¿ƒã€‚"
                ]
            
            selected_comment = random.choice(comments)
            
            # æ·»åŠ APIé…ç½®æç¤ºï¼ˆéšæœºå‡ºç°ï¼‰
            if random.random() < 0.3:  # 30%çš„æ¦‚ç‡æ˜¾ç¤ºæç¤º
                selected_comment += "\n\nğŸ’¡ æç¤ºï¼šé…ç½®DeepSeek APIå¯†é’¥å¯è·å¾—æ›´æ™ºèƒ½çš„ä¸ªæ€§åŒ–è¯„è®ºï¼"
            
            return selected_comment
        
        # æ„å»ºè¯·æ±‚
        url = f"{base_url}/chat/completions"
        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {api_key}"
        }
        
        prompt = f"è¯·ä¸ºä»¥ä¸‹åˆ›æ„å†…å®¹ç”Ÿæˆä¸€ä¸ªå‹å–„ã€å»ºè®¾æ€§çš„è¯„è®ºï¼ˆ50-80å­—ï¼‰ï¼š\næ ‡é¢˜ï¼š{title}\nå†…å®¹ï¼š{content[:300]}..."
        
        data = {
            "model": "deepseek-chat",
            "messages": [
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªå‹å–„çš„å†…å®¹è¯„è®ºåŠ©æ‰‹ï¼Œèƒ½å¤Ÿä¸ºå„ç§åˆ›æ„å†…å®¹ç”Ÿæˆç§¯æã€å»ºè®¾æ€§çš„è¯„è®ºã€‚è¯„è®ºåº”è¯¥é¼“åŠ±ä½œè€…ï¼ŒåŒæ—¶æä¾›æœ‰ä»·å€¼çš„åé¦ˆã€‚"},
                {"role": "user", "content": prompt}
            ],
            "max_tokens": 120,
            "temperature": 0.8,
            "stream": False
        }
        
        response = requests.post(url, headers=headers, json=data, timeout=30)
        
        if response.status_code == 200:
            result = response.json()
            if 'choices' in result and len(result['choices']) > 0:
                comment = result['choices'][0]['message']['content'].strip()
                return comment
            else:
                return "å¾ˆæ£’çš„åˆ›æ„ï¼æ„Ÿè°¢åˆ†äº«è¿™ä¹ˆæœ‰ä»·å€¼çš„å†…å®¹ã€‚"
        else:
            print(f"DeepSeek APIé”™è¯¯: {response.status_code} - {response.text}")
            return "å¾ˆæ£’çš„åˆ›æ„ï¼æ„Ÿè°¢åˆ†äº«è¿™ä¹ˆæœ‰ä»·å€¼çš„å†…å®¹ã€‚"
            
    except Exception as e:
        print(f"AIç‚¹è¯„ç”Ÿæˆé”™è¯¯: {e}")
        return "å¾ˆæ£’çš„åˆ›æ„ï¼æ„Ÿè°¢åˆ†äº«è¿™ä¹ˆæœ‰ä»·å€¼çš„å†…å®¹ã€‚"


def create_ai_user():
    """åˆ›å»ºæˆ–è·å–AIç”¨æˆ·"""
    from django.contrib.auth.models import User
    from .models import UserProfile
    
    try:
        ai_user, created = User.objects.get_or_create(
            username='AIåŠ©æ‰‹',
            defaults={
                'email': 'ai@example.com',
                'first_name': 'AI',
                'last_name': 'åŠ©æ‰‹',
                'is_active': True
            }
        )
        
        # åˆ›å»ºæˆ–æ›´æ–°ç”¨æˆ·èµ„æ–™
        profile, profile_created = UserProfile.objects.get_or_create(
            user=ai_user,
            defaults={
                'bio': 'æˆ‘æ˜¯AIæ™ºèƒ½åŠ©æ‰‹ï¼Œç”±DeepSeek AIé©±åŠ¨ï¼Œä¸“é—¨ä¸ºç”¨æˆ·æä¾›æ™ºèƒ½è¯„è®ºå’Œå†…å®¹åˆ†æã€‚',
                'location': 'äº‘ç«¯',
                'website': 'https://www.deepseek.com'
            }
        )
        
        return ai_user
    except Exception as e:
        print(f"åˆ›å»ºAIç”¨æˆ·å¤±è´¥: {e}")
        return None


def create_ai_comment_for_content(content_obj):
    """ä¸ºæŒ‡å®šå†…å®¹åˆ›å»ºAIè¯„è®º"""
    from .models import Comment
    
    try:
        ai_user = create_ai_user()
        if not ai_user:
            return None
            
        # æ£€æŸ¥æ˜¯å¦å·²ç»æœ‰AIè¯„è®ºï¼ˆé™åˆ¶æ¯ä¸ªå†…å®¹æœ€å¤šä¸€ä¸ªAIè¯„è®ºï¼‰
        existing_comment = Comment.objects.filter(
            content=content_obj,
            author=ai_user
        ).first()
        
        if existing_comment:
            # å¦‚æœå·²å­˜åœ¨AIè¯„è®ºï¼Œé‡æ–°ç”Ÿæˆå¹¶æ›´æ–°è¯„è®ºå†…å®¹
            ai_comment_text = generate_ai_comment(content_obj.title, content_obj.content)
            existing_comment.text = ai_comment_text
            existing_comment.save()
            return existing_comment
            
        # ç”ŸæˆAIè¯„è®º
        ai_comment_text = generate_ai_comment(content_obj.title, content_obj.content)
        
        # åˆ›å»ºè¯„è®º
        comment = Comment.objects.create(
            content=content_obj,
            author=ai_user,
            text=ai_comment_text
        )
        
        return comment
    except Exception as e:
        print(f"åˆ›å»ºAIè¯„è®ºå¤±è´¥: {e}")
        return None


def get_trending_tags(days=7, limit=10):
    """è·å–çƒ­é—¨æ ‡ç­¾"""
    from django.utils import timezone
    from datetime import timedelta
    
    since_date = timezone.now() - timedelta(days=days)
    
    trending_tags = Tag.objects.filter(
        creativecontent__created_at__gte=since_date
    ).annotate(
        content_count=Count('creativecontent'),
        total_likes=Count('creativecontent__likes'),
        total_favorites=Count('creativecontent__favorites')
    ).filter(
        content_count__gt=0
    ).order_by(
        '-total_likes',
        '-total_favorites',
        '-content_count'
    )[:limit]
    
    return trending_tags


def calculate_content_score(content):
    """è®¡ç®—å†…å®¹ç»¼åˆè¯„åˆ†"""
    # åŸºç¡€åˆ†æ•°
    base_score = 0
    
    # ç‚¹èµæ•°æƒé‡
    likes_score = content.likes_count * 1
    
    # æ”¶è—æ•°æƒé‡
    favorites_score = content.favorites_count * 2
    
    # è¯„è®ºæ•°æƒé‡
    comments_score = content.comments_count * 0.5
    
    # æµè§ˆæ•°æƒé‡
    views_score = content.views_count * 0.1
    
    # è¯„åˆ†æƒé‡
    rating_score = 0
    if content.ratings.exists():
        avg_rating = content.ratings.aggregate(avg=Avg('score'))['avg'] or 0
        rating_score = avg_rating * 2
    
    # æ—¶é—´è¡°å‡ï¼ˆæ–°å†…å®¹æœ‰åŠ åˆ†ï¼‰
    from django.utils import timezone
    days_old = (timezone.now() - content.created_at).days
    time_factor = max(0.1, 1 - (days_old * 0.05))  # æ¯å¤©è¡°å‡5%
    
    total_score = (
        base_score + likes_score + favorites_score + 
        comments_score + views_score + rating_score
    ) * time_factor
    
    return round(total_score, 2)